# üçª BEES Data Engineering - Breweries Case

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue)](https://www.python.org/)
[![Airflow](https://img.shields.io/badge/Airflow-2.5%2B-orange)](https://airflow.apache.org/)

Reposit√≥rio do projeto de engenharia de dados para consumo e processamento de dados de cervejarias utilizando arquitetura medallion.

##  Objetivo

Implementar um pipeline de dados que:
1. Consome dados da [Open Brewery DB API](https://www.openbrewerydb.org/)
2. Processa seguindo a arquitetura medallion:
   - Bronze (dados brutos)
   - Silver (dados curados)
   - Gold (dados anal√≠ticos)
3. Particiona dados por localiza√ß√£o geogr√°fica


 # Projeto de Extra√ß√£o de Dados de Cervejarias

Pipeline para extra√ß√£o de dados de cervejarias pr√≥ximas a determinadas coordenadas geogr√°ficas.

##  Vis√£o Geral

Este projeto extrai dados b√°sicos de cervejarias pr√≥ximas a uma localiza√ß√£o espec√≠fica usando a [Open Brewery DB API](https://www.openbrewerydb.org/).

## Tecnologias

- **Linguagem**: Python 3.9+
- **Orquestra√ß√£o**: Apache Airflow 2.5+
- **Armazenamento**: SQLite (dev) / PostgreSQL (prod)
- **Processamento**: Pandas, PySpark
- **Infraestrutura**: Docker, Docker-compose
- **Monitoramento**: Prometheus + Grafana

## Configura√ß√£o

```bash
# 1. Clonar reposit√≥rio
git clone https://github.com/Laerterp/brewery-data-pipeline.git

# 2. Configurar ambiente
cd brewery-data-pipeline
cp .env.example .env

# 3. Iniciar containers
docker-compose up -d

bash
python extraction.py
Os dados ser√£o salvos em data/bronze/breweries_raw/ com timestamp no nome do arquivo.

##Configura√ß√µes Personaliz√°veis
Edite no c√≥digo:

LATITUDE e LONGITUDE: Coordenadas geogr√°ficas de refer√™ncia

PER_PAGE: N√∫mero de resultados por requisi√ß√£o (max 200 pela API)

OUTPUT_DIR: Diret√≥rio de sa√≠da dos dados brutos

##  Camada Bronze (Raw) 
**Formato**: JSON bruto (exatamente como recebido da API)  
**Cont√©m**:
- `id`: Identificador √∫nico (string)
- `name`: Nome da cervejaria (string)
- `brewery_type`: Micro/brewpub/etc (string)
- `address_1/2/3`: Endere√ßo completo (string|null)
- `latitude/longitude`: Coordenadas (float|null)
- `website_url`: URL (string|null)
- `updated_at`: Timestamp (string ISO 8601)

**Exemplo de arquivo**:
```json
{
  "id": "10-56-brewing-company-oxnard",
  "name": "10-56 Brewing Company",
  "brewery_type": "micro",
  "street": "302 North Ventura Road",
  "city": "Oxnard",
  "state": "California",
  "postal_code": "93030",
  "country": "United States",
  "longitude": "-119.2072836",
  "latitude": "34.2748005",
  "website_url": "http://www.1056brewingcompany.com"
}

Camada Silver (Processed) ‚Üí Pr√≥xima etapa do pipeline
Diferen√ßas-chave:

Estrutura normalizada (tabelas relacionais)

**Objetivo**: Dados limpos, normalizados e prontos para an√°lise

### Transforma√ß√µes Realizadas

1. **Tratamento de Valores Nulos**:
   ```python
   df.fillna({
       'address_2': '',
       'address_3': '',
       'phone': 'N/A',
       'website_url': 'N/A',
       'longitude': 0.0,
       'latitude': 0.0
   }, inplace=True)

   2. Convers√£o de Tipos:

Endere√ßos secund√°rios para string

Telefones como texto (preservando formatos)

CEPs como string (mesmo contendo n√∫meros)

## Estrutura Final (Parquet)
Coluna	Tipo	Descri√ß√£o	Exemplo
id	string	ID √∫nico	"10-56-brewing-company"
name	string	Nome da cervejaria	"Stone Brewing"
tipos_cervejaria	string	Micro/brewpub/etc	"micro"
street	string	Endere√ßo principal	"302 N Ventura Rd"
location	string	Localiza√ß√£o completa	"Oxnard, CA, US"
processed_at	timestamp	Quando foi processado	"2024-06-15 14:30:00"

## Armazenamento
python
df.to_parquet(
    "data/silver/breweries_bycity.parquet",
    engine='pyarrow',
    compression='snappy'
)

## Particionamento na Camada Silver

**Objetivo**: Otimizar consultas por localiza√ß√£o geogr√°fica

### Estrutura de Particionamento
```bash
data/silver/
‚îî‚îÄ‚îÄ breweries_partitioned/
    ‚îú‚îÄ‚îÄ estado_provincia=California/
    ‚îÇ   ‚îú‚îÄ‚îÄ city=San Diego/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ part-00000.parquet
    ‚îÇ   ‚îî‚îÄ‚îÄ city=Los Angeles/
    ‚îÇ       ‚îî‚îÄ‚îÄ part-00001.parquet
    ‚îî‚îÄ‚îÄ estado_provincia=New York/
        ‚îî‚îÄ‚îÄ city=New York/
            ‚îî‚îÄ‚îÄ part-00002.parquet

# Particionamento por estado e cidade
partition_cols = ['estado_provincia', 'city']
df.to_parquet(
    "data/silver/breweries_partitioned",
    partition_cols=partition_cols,
    engine='pyarrow',
    compression='snappy'
)

# Exemplo: Consulta eficiente para San Diego
pd.read_parquet(
    "data/silver/breweries_partitioned/estado_provincia=California/city=San Diego"
)
Custo-Efici√™ncia: Ler apenas parti√ß√µes relevantes reduz I/O

Organiza√ß√£o: Estrutura auto-documentada


üìä ## Camada Silver para SQLite (Persist√™ncia)

**Objetivo**: Criar um banco de dados relacional para an√°lise ad-hoc e prepara√ß√£o da camada Gold

### Fluxo Completo
```mermaid
graph LR
    A[Bronze: JSON] --> B(Silver: Parquet)
    B --> C{SQLite}
    C --> D[Gold: An√°lises]

 C√≥digo de Carga
python
# silver_to_sqlite.py
import sqlite3
import pandas as pd
from glob import glob

# 1. Carrega todos os Parquets particionados
parquet_files = glob("data/silver/**/*.parquet", recursive=True)

# 2. Conecta ao SQLite
conn = sqlite3.connect("data/breweries.db")

# 3. Cria tabelas para cada parti√ß√£o
for file in parquet_files:
    df = pd.read_parquet(file)
    table_name = "breweries_" + file.split("/")[-2].replace("=", "_")  # Ex: breweries_estado_provincia_CA
    df.to_sql(table_name, conn, if_exists='replace', index=False)

Pr√≥ximos passos --- üìä Modelagem Dimensional (Camada Gold)
A modelagem dimensional foi implementada com base em um esquema estrela, otimizando a consulta anal√≠tica e facilitando agrega√ß√µes de dados por localiza√ß√£o, tipo e status operacional das cervejarias.

Essa estrutura permite responder perguntas como:

Quantas cervejarias existem por estado e tipo?

Qual a propor√ß√£o de microcervejarias em determinado pa√≠s?

Como as cervejarias coreanas se comparam globalmente?

üõ†Ô∏è Estrutura do Esquema Estrela
mermaid
Copiar
Editar
erDiagram
    FACT_BREWERIES ||--o{ DIM_LOCATION : "localiza"
    FACT_BREWERIES ||--|{ DIM_BREWERY_TYPE : "classifica"
    FACT_BREWERIES ||--o{ DIM_STATUS : "possui"
    FACT_BREWERIES {
        string brewery_id PK
        int location_id FK
        int type_id FK
        int status_id FK
        date created_at
        date updated_at
    }
üó∫Ô∏è Dimens√£o Geogr√°fica ‚Äì dim_location
Hierarquia natural: Country ‚Üí State ‚Üí City ‚Üí Postal Code.

A tabela geogr√°fica foi constru√≠da a partir dos dados √∫nicos de cidade, estado e pa√≠s, com identifica√ß√£o por location_id:

Campo	Descri√ß√£o
city	Cidade da cervejaria
state	Estado/prov√≠ncia
country	Pa√≠s
postal_code	C√≥digo postal (zipcode)
latitude/longitude	Coordenadas geogr√°ficas
full_location_description	Texto completo do local

Apenas registros com cidade e pa√≠s foram considerados v√°lidos.

üç∫ Dimens√£o de Tipo ‚Äì dim_tipocervejarias
Essa dimens√£o categoriza o tipo de cervejaria com uma descri√ß√£o leg√≠vel, √∫til para filtros e segmenta√ß√µes.

brewery_type (API)	Descri√ß√£o leg√≠vel
micro	Microcervejaria
brewpub	Pub cervejeiro
large	Grande cervejaria
planning	Planejamento
contract	Contrato
closed	Fechada
regional	Regional
outros	Outro tipo

‚úÖ Dimens√£o de Status ‚Äì dim_status
Criada com base na presen√ßa ou aus√™ncia de telefone. Aus√™ncia indica cervejaria inativa.

Status	Descri√ß√£o Operacional
Ativo	Cervejaria operacional
Inativo	Cervejaria n√£o operacional (sem telefone)

üßÆ Tabela Fato ‚Äì fact_breweries
A tabela fato conecta todas as dimens√µes e armazena os registros √∫nicos de cada cervejaria, permitindo an√°lises cruzadas.

Campo	Descri√ß√£o
brewery_id	ID √∫nico da cervejaria
location_id	FK para localiza√ß√£o geogr√°fica
type_id	FK para tipo de cervejaria
status_id	FK para status operacional
created_at	Data de inser√ß√£o
updated_at	Data da √∫ltima atualiza√ß√£o

üîç Exemplos de Consultas Anal√≠ticas
1. Distribui√ß√£o Geogr√°fica por Tipo
sql
Copiar
Editar
SELECT 
    l.country,
    l.state,
    t.brewery_type,
    COUNT(*) AS count,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY l.country, l.state), 1) AS percentage
FROM fact_breweries f
JOIN dim_location l ON f.location_id = l.location_id
JOIN dim_tipocervejarias t ON f.type_id = t.type_id
GROUP BY 1, 2, 3;
2. An√°lise com Microcervejarias (Externa)
SELECT 
    COALESCE(l.state, k.state) AS state,
    COALESCE(l.country, 'South Korea') AS country,
    c.tipos_cervejaria,
    COUNT(DISTINCT c.id) AS brewery_count,
    k.brewery_count AS korean_brewery_count
FROM 
    consolidated_breweries c
LEFT JOIN 
    dim_location l ON c.state = l.state AND c.country = l.country
LEFT JOIN 
    korean_breweries_by_state_20250614_192933 k ON c.state = k.state
GROUP BY 
    COALESCE(l.state, k.state),
    COALESCE(l.country, 'South Korea'),
    c.tipos_cervejaria,
    k.brewery_count
ORDER BY 
    COALESCE(l.country, 'South Korea'), 
    COALESCE(l.state, k.state);

üç∫ Quantidade de Cervejarias por Tipo e Localiza√ß√£o
Estado/Prov√≠ncia	Pa√≠s	Tipo	Quantidade
Bouche du Rh√¥ne	France	micro	1
Gangwondo	South Korea	brewpub	1
Jeollabukdo	South Korea	brewpub	1
Seoul	South Korea	brewpub	1
California	United States	brewpub	14
California	United States	closed	4
California	United States	contract	1
California	United States	large	5
California	United States	micro	24
California	United States	planning	3
California	United States	regional	2
Colorado	United States	brewpub	1
Oklahoma	United States	micro	1
Texas	United States	micro	1
Wisconsin	United States	micro	1

Essa view responde a umas das perguntas do case que √© quantidade de cervejarias por tipo e localiza√ß√£o.

üéØ Benef√≠cios da Modelagem
Estrutura simplificada para an√°lise com ferramentas como Power BI e Tableau.

Performance otimizada com uso de formato columnar (ex: Parquet na camada Silver).

Flexibilidade para integrar fontes externas (ex: Coreia, microcervejarias).

Facilidade na constru√ß√£o de dashboards e KPIs.




## Demonstra√ß√£o de Conhecimento em Orquestra√ß√£o de Dados com Apache Airflow

Documenta√ß√£o do Pipeline de Dados de Cervejaria
Ferramenta de Orquestra√ß√£o: Apache Airflow (Docker)
Reposit√≥rio: brewery-data-pipeline

1. Estrutura Atual
1.1 Containers Docker
Servi√ßos Principais:

airflow-apiserver: Interface web (porta 8080)

airflow-scheduler: Agendamento de DAGs

airflow-worker: Execu√ß√£o de tarefas

postgres: Banco de dados (porta 5432)

redis: Broker para Celery (porta 6379)

1.2 Diret√≥rios
dags/: Armazena as DAGs (ex: brewery_pipeline.py)

logs/: Logs de execu√ß√£o

plugins/: Operadores customizados (se necess√°rio)

1.3 Credenciais Padr√£o
Airflow UI: http://localhost:8080

Usu√°rio: airflow

Senha: airflow

2. Monitoramento e Alertas
2.1 Objetivos
Detectar falhas no pipeline (erros em tarefas).

Identificar problemas de qualidade (dados inconsistentes, nulos, etc.).

Alertar em tempo real via Slack e e-mail.

2.2 Implementa√ß√£o
A. Monitoramento B√°sico
Ferramenta	Fun√ß√£o
Airflow UI	Visualiza√ß√£o manual do status das DAGs (Success, Failed, Running).
Prometheus	Coleta m√©tricas (ex: tempo de execu√ß√£o, tarefas falhas).
Grafana	Dashboard com m√©tricas em tempo real (ex: DAGs falhas nas √∫ltimas 24h).
B. Alertas Automatizados
Canal	Configura√ß√£o
E-mail	Vari√°veis no docker-compose.yaml (SMTP) + email_on_failure=True nas DAGs.
Slack	Webhook + Callback nas DAGs (ex: on_failure_callback=slack_fail_alert).
Exemplo de Callback para Slack:

python
def slack_fail_alert(context):  
    message = f"""  
    :red_circle: Falha na DAG `{context['dag'].dag_id}`.  
    *Tarefa*: `{context['task'].task_id}`  
    *Erro*: `{context['exception']}`  
    *Log*: {context['task_instance'].log_url}  
    """  
    SlackWebhookOperator(  
        task_id='slack_alert',  
        slack_webhook_conn_id='slack_default',  
        message=message  
    ).execute(context)  
C. Valida√ß√£o de Dados
Checks na DAG:

python
def validate_data(**context):  
    data = context['ti'].xcom_pull(task_ids='extract_data')  
    if data.empty:  
        raise ValueError("Dados vazios!")  
    if data.duplicated().sum() > 0:  
        context['ti'].log.warning("Dados duplicados encontrados!")  
Ferramentas:

Great Expectations: Valida esquemas e estat√≠sticas dos dados.

SQL Operators: Consultas para verificar consist√™ncia no PostgreSQL.

3. Tratamento de Falhas
Estrat√©gia	Implementa√ß√£o
Retentativas	retries=3 e retry_delay=timedelta(minutes=5) nas DAGs.
Timeouts	execution_timeout=timedelta(minutes=30) para evitar tarefas travadas.
Depend√™ncias	Uso de ExternalTaskSensor para verificar pr√©-requisitos.
4. Pr√≥ximos Passos
Adicionar testes automatizados para as DAGs (ex: com pytest).

Implementar dashboards no Grafana (ex: taxa de falhas, tempo m√©dio de execu√ß√£o).

Alertas para qualidade de dados (ex: notificar se >5% dos registros forem nulos).

Como Executar
Iniciar containers:

bash
docker-compose -f docker-compose.yaml up -d  
Acessar o Airflow:
http://localhost:8080

Adicionar DAGs:
Salve arquivos .py em dags/.


‚úçÔ∏è Autor

Laerte Rocha Neves
